# Centralizador de Logs com Kafka, Loki e Grafana

Este projeto implementa um pipeline completo de ingestÃ£o de logs:

- **API Fastify (Node.js)**: Recebe logs via HTTP (JSON).
- **Worker Java (Spring Boot)**: Consome logs do Kafka e envia para o Loki.
- **Kafka**: Fila intermediÃ¡ria de logs para garantir resiliÃªncia.
- **Loki**: Armazenamento leve e eficiente para logs.
- **Grafana**: VisualizaÃ§Ã£o dos logs.

---

## ðŸ“¦ Tecnologias

- Node.js + Fastify
- Java + Spring Boot + Kafka Client + WebClient
- Apache Kafka
- Grafana + Loki
- Docker Compose

---

## ðŸš€ Como executar

1. **Clone o repositÃ³rio:**

```bash
git clone url
cd centralizador-logs
```

2. **Suba os serviÃ§os com Docker Compose:**
```bash
docker compose up --build
```

3. **Acesse o Grafana:**
- URL: http://localhost:3000
- UsuÃ¡rio: admin
- Senha: admin

4. **Configure o Loki como fonte de dados:**
- Configuration â†’ Data Sources â†’ Add data source â†’ Loki
- URL: http://loki:3100

5. **Envie um log de teste para a API:**
```bash
curl -X POST http://localhost:4000/logs \
  -H "Content-Type: application/json" \
  -d '{
    "service": "auth-service",
    "level": "error",
    "message": "Falha ao autenticar usuÃ¡rio",
    "timestamp": "2025-07-22T20:00:00Z",
    "context": {
      "userId": "123",
      "ip": "192.168.1.100"
    }
  }'
```

